{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://github.com/kamu-data/kamu-cli\">\n",
    "<img alt=\"kamu\" src=\"https://raw.githubusercontent.com/kamu-data/kamu-cli/master/docs/readme_files/kamu_logo.png\" width=270/>\n",
    "</a>\n",
    "</center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<center><i>World's first decentralized real-time data warehouse, on your laptop</i></center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div align=\"center\">\n",
    "<a href=\"https://github.com/kamu-data/kamu-cli\">Repo</a> | \n",
    "<a href=\"https://docs.kamu.dev/cli/\">Docs</a> | \n",
    "<a href=\"https://docs.kamu.dev/cli/learn/learning-materials/\">Tutorials</a> | \n",
    "<a href=\"https://docs.kamu.dev/cli/learn/examples/\">Examples</a> |\n",
    "<a href=\"https://docs.kamu.dev/cli/get-started/faq/\">FAQ</a> |\n",
    "<a href=\"https://discord.gg/nU6TXRQNXC\">Discord</a> |\n",
    "<a href=\"https://kamu.dev\">Website</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "    \n",
    "# 1. Working with Web3 data\n",
    "\n",
    "</center>\n",
    "\n",
    "# Introduction\n",
    "\n",
    "No matter if you are Blockchain-cautios, Web3-courious, or already own a mansion in the Metaverse - you'll probably agree that the Distributed Ledgers (Blockchains) are quickly becoming **very large sources of various data**. And we really like data!\n",
    "\n",
    "Web 2/3 worlds of data, hovever, are still very fragmented:\n",
    "\n",
    "* Web2 data sits in thousands of silos, in hundreds of different formats, or hidden behind custom JSON APIs which take weeks to integrate. We are still very far from achieving interoperability of data even in the Web2 world alone.\n",
    "\n",
    "* Web3 data from public ledgers, despite being freely available, presents an big challenge in terms of its volumes and non-friendly to Data Science formats. Some projects like [The Graph](https://thegraph.com/) and [Dune](https://dune.com/) make it more accessible, but don't offer much help when you want to combine data from Web2 and Web3. Any even slightly more advanced use case often requires developing your own data ingestion infrastructure which most of us cannot afford.\n",
    "\n",
    "What if we could solve both of these problems with a **single technology**? Make data overall much more easily **accessible** and **interoperable**, and erase the boundary between **off- and on-chain data**.\n",
    "\n",
    "In this demo we will see how `kamu`'s data pipelines can make this possible, allowing you to share data using modern Web3 decentralized storage systems, and letting you easily combine on- and off-chain data within a single query.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "This demo is intended to be standalone, but if at any point in time you feel lost you might want to revisit the _\"Kamu Basics\"_ chapter first. You are also very welcome on our [Discord](https://discord.gg/nU6TXRQNXC) or can create an issue in [kamu-cli](https://github.com/kamu-data/kamu-cli) GitHub repository to get help.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case\n",
    "\n",
    "But first we need to pick a use case, so why don't we do some **personal finance**?\n",
    "\n",
    "You like financial planning, don't you?\n",
    "\n",
    "Neither do we... Being a grown up and having to deal with multiple bank accounts and retirement plans - what can be more boring?\n",
    "\n",
    "But perhaps you spice things up by holding some cryptocurrency ... except now all your money are **spread over multiple different institutions and wallets** and it's very easy to **lose track** of your overall financial situation.\n",
    "\n",
    "Most tools that banks and wallet apps offer are already mediocre, but now they are of no use at all as they only show you small parts of the whole picture.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Fun fact: `kamu` started in 2018 as a huge set of scripts that ingested data from multiple bank, retirement, and investment accounts, unified all currencies, and analyzed the performance of investments over time. This pipeline was so painful to maintain that we started to look for a better, fully autonomous solution.\n",
    "\n",
    "</div>\n",
    "\n",
    "For this demo let's assume that you **had some Ethereum**. To get more upside while holding it you decided to **\"stake\" it in the [Rocketpool](https://rocketpool.net/)**.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<details>\n",
    "<summary style=\"display:list-item\"><b>What is Staking?</b></summary>\n",
    "\n",
    "Staking is when you lock up some of your Ethereum as a collateral and to become a validator of ledger transactions. Staking pools like _Rocketpool_ allow you to invest any amount of ETH and let other people operate the transaction validator nodes for you while you all share the validation rewards.\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "Few month later you start wondering:\n",
    "- Was that a good investment?\n",
    "- How much is it worth now and what is the return?\n",
    "- How did it perform over time compared to other things you invest in?\n",
    "\n",
    "These questions are so easy to ask, but **so hard to answer**!\n",
    "\n",
    "Throughout this demo we will create a personal data pipeline that can not only provide you an answer, but one that can **constantly stay up-to-date**, giving you full awareness of your portfolio's performance.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "This demo should not be taken as a financial advice or a comment on cryptocurrency - we are only interested in data science aspects of it.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Our first pipeline will look like this:\n",
    "\n",
    "![blah](files/pipeline-1.png)\n",
    "\n",
    "```\n",
    "┌───────────────────────────────────────┬──────────────┬─────────────────────────────────────────────────┐\n",
    "│                 Name                  │     Kind     │                  Description                    │\n",
    "├───────────────────────────────────────┼──────────────┼─────────────────────────────────────────────────┤\n",
    "│ net.rocketpool.reth.mint-burn         │ Remote(Root) │ rETH transactions (pulled from IPFS)            │\n",
    "│ com.cryptocompare.ohlcv.eth-usd       │ Remote(Root) │ ETH to USD exchange rate (pulled from IPFS)     │\n",
    "│ account.tokens.transfers              │     Root     │ Wallet token transfers (sourced from Etherscan) │\n",
    "│ account.transactions                  │     Root     │ Wallet transactions (sourced from Etherscan)    │\n",
    "│ account.tokens.portfolio              │  Derivative  │ Tokens portfolio with book prices & amount held │\n",
    "│ account.tokens.portfolio.usd          │  Derivative  │ Tokens portfolio with USD book prices           │\n",
    "│ account.tokens.portfolio.market-value │  Derivative  │ Tokens portfolio market value in ETH and USD    │\n",
    "└───────────────────────────────────────┴──────────────┴─────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting datasets from IPFS\n",
    "When you stake your `ETH` in Rocketpool - the Smart Contract takes your `ETH` and issues you a corresponding amount of `rETH` tokens to represent your stake.\n",
    "\n",
    "Instead of periodically sending you more `rETH`, your staking rewards are \"delivered\" by changing the exchange rate between `ETH` and `rETH`, e.g. if you paid `1 ETH` for `1 rETH` in 2021, in 2022 you could sell `1 rETH` for `1.024 ETH` i.e. a 2.4% gain.\n",
    "\n",
    "Let's try to visualize these exchange rates.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "First, we initialize our workspace:\n",
    "    \n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">cd \"02 - Web3 Data (Ethereum trading example)\"\n",
    "kamu init\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Since Ethereum is an open data source - we can find out the exchange rates by simply looking at all blockchain transactions involving `rETH` contract and seeing how much people buy and sell it for.\n",
    "\n",
    "We believe that <mark>getting data should be easy</mark>, so before we explain how data gets into the network (see chapter XXXXXXXXXX), let's see **how easy it is to get data that's already in Open Data Fabric**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Run the following command:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">kamu pull \"ipns://net.rocketpool.reth.mint-burn.ipns.kamu.dev\" --as net.rocketpool.reth.mint-burn\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Pulling from IPFS may take a few minutes, so if you'd like to sacrifice the full \"decentralized data experience\" for speed you can also pull data from S3:\n",
    "    \n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">kamu pull \"https://s3.us-west-2.amazonaws.com/datasets.kamu.dev/odf/v1/contrib/net.rocketpool.reth.mint-burn\"\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Lots of cool things are happening in this one command:\n",
    "- Beforehand we prepared a [rETH transactions](https://github.com/kamu-data/kamu-cli/blob/master/images/demo/user-home/02%20-%20Web3%20Data%20%28Ethereum%20trading%20example%29/datasets/rocketpool.reth.mint-burn.yaml) dataset for you\n",
    "- A [periodic job](https://github.com/kamu-data/kamu-contrib/actions) uses `kamu` to ingests new data from an Ethereum node\n",
    "- Dataset is stored in [IPFS](https://ipfs.io) - an \"Inter-Planetary File System\"\n",
    "- Using DNS everyone can refer to this dataset as `ipns://net.rocketpool.reth.mint-burn.ipns.kamu.dev`\n",
    "- The DNS record resolves into an IPFS hash (`CID`) of the latest version of the dataset\n",
    "- `kamu` uses the CID to download the entire dataset block-by-block\n",
    "- Next time you do `kamu pull net.rocketpool.reth.mint-burn` only the new blocks will be downloaded (i.e. a minimal update)\n",
    "\n",
    "So we are pulling <mark>**public ledger**</mark> data that is parsed into <mark>**analytical data format**</mark> by <mark>**verifiable code**</mark> and stored in a <mark>**globally-decentralized file system**</mark> as a <mark>**near-real-time data stream**</mark>.\n",
    "\n",
    "...Neat!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Try out the following commands (add `--help` to read what they do):\n",
    "    \n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">kamu list\n",
    "kamu tail net.rocketpool.reth.mint-burn\n",
    "kamu log net.rocketpool.reth.mint-burn\n",
    "kamu inspect schema net.rocketpool.reth.mint-burn\n",
    "kamu repo alias list\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data is in, now let's visualize it.\n",
    "\n",
    "If you run `kamu tail` - you can see that this dataset contains all individual transactions that involved rETH token.\n",
    "\n",
    "Based on the [ERC-20 Token Standard](https://ethereum.org/en/developers/docs/standards/tokens/erc-20/) we know that when token is issued in exchange for `ETH` - the `TokensMinted` event is present in Ethereum transaction logs, and when `rETH` is exchanged back into `ETH` - we expect the `TokensBurned` event.\n",
    "\n",
    "Using this we can now create the **instantaneous buy/sell exchange rate graph**:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<details>\n",
    "<summary style=\"display:list-item\">Need a quick refresher on using <b>kamu's Jupyter notebooks</b>?</summary>\n",
    "\n",
    "Jupyter notebook you're using now runs either on our demo server (https://demo.kamu.dev) or can be launched with `kamu notebook` command in your own workspace when you have the tool installed.\n",
    "    \n",
    "To start working with data:\n",
    "- First run `%load_ext kamu` to load our extension\n",
    "- Then use `%import_dataset dataset_name` to import datasets from your workspace\n",
    "\n",
    "Above commands will start the Apache Spark SQL server in the background and connect to it.\n",
    "    \n",
    "By default all code cells execute in PySpark environment, which is most of the time not what we want.\n",
    "    \n",
    "Instead we use `%%sql` cells to run SQL queries in Spark. It's a great way to explore and shape your data.\n",
    "    \n",
    "You can download the result of any SQL query into the notebook's Python process using `%%sql -o pandas_dataframe_variable -n records_limit`.\n",
    "    \n",
    "You can then use `%%local` cells to execute Python code inside the notebook to further process or visualize the data.\n",
    "    \n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext kamu\n",
    "%import_dataset net.rocketpool.reth.mint-burn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from `net.rocketpool.reth.mint-burn` limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -o reth_pool -q\n",
    "\n",
    "--## The -o <name> option above downloads the SQL query result\n",
    "--## into the local notebook as Pandas dataframe\n",
    "select \n",
    "    event_time, \n",
    "    case \n",
    "        when event_name = \"TokensMinted\" then \"Mint\"\n",
    "        when event_name = \"TokensBurned\" then \"Burn\"\n",
    "    end as event_name, \n",
    "    avg(eth_amount / amount) as rate\n",
    "from `net.rocketpool.reth.mint-burn` \n",
    "group by event_time, event_name\n",
    "order by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "reth_pool.hvplot.step(\n",
    "    x=\"block_time\", \n",
    "    by=\"event_name\", \n",
    "    width=900, height=600, \n",
    "    legend='top_left', grid=True, \n",
    "    title=\"ETH : rETH Ratio (Minting and Burning)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can tell that Rocketpool so far is fulfilling its promise of steady staking returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ETH to USD exchange rate\n",
    "\n",
    "While we're at it, let's also use the same mechanism to get the ETH to USD exchange rate:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Pull existing dataset from IPFS:\n",
    "    \n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">kamu pull \"ipns://com.cryptocompare.ohlcv.eth-usd.ipns.kamu.dev\" --as com.cryptocompare.ohlcv.eth-usd\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Pulling from IPFS may take a few minutes, so if you'd like to sacrifice the full \"decentralized data experience\" for speed you can also pull data from S3:\n",
    "    \n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">kamu pull \"https://s3.us-west-2.amazonaws.com/datasets.kamu.dev/odf/v1/contrib/com.cryptocompare.ohlcv.eth-usd\"\n",
    "</code>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%import_dataset com.cryptocompare.ohlcv.eth-usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from `com.cryptocompare.ohlcv.eth-usd` \n",
    "order by event_time desc \n",
    "limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -o eth2usd -q\n",
    "select * from `com.cryptocompare.ohlcv.eth-usd` order by event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "eth2usd.hvplot.line(\n",
    "    x=\"event_time\",\n",
    "    y=\"close\",\n",
    "    height=500, \n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting Account Data from Etherscan\n",
    "Let's get data about our account now.\n",
    "\n",
    "This dataset will be personalized, so we don't have it prepared. Instead, we will create our own Root datasets using data from the [Etherscan API](https://etherscan.io/) (free API tier will be enough for our needs).\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Add datasets and pull data:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">kamu add datasets/account.tokens.transfers.yaml datasets/account.transactions.yaml\n",
    "kamu pull account.tokens.transfers account.transactions\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "The key part of the `account.tokens.transfers` dataset manifest is:\n",
    "```yaml\n",
    "kind: DatasetSnapshot\n",
    "version: 1\n",
    "content:\n",
    "  name: account.tokens.transfers\n",
    "  kind: root\n",
    "  metadata:\n",
    "    - kind: setPollingSource\n",
    "      fetch:\n",
    "        kind: url\n",
    "        url: \"https://api.etherscan.io/api\\\n",
    "          ?module=account\\\n",
    "          &action=tokentx\\\n",
    "          &address=0xeadb3840596cabf312f2bc88a4bb0b93a4e1ff5f\\\n",
    "          &page=1\\\n",
    "          &offset=1000\\\n",
    "          &startblock=0\\\n",
    "          &endblock=99999999\n",
    "      prepare: ...\n",
    "      read: ...\n",
    "      preprocess: ...\n",
    "      merge:\n",
    "        kind: ledger\n",
    "        primaryKey:\n",
    "          - transaction_hash\n",
    "```\n",
    "\n",
    "We are asking Etherscan to return us all ERC-20 token transactions involving account `0xeadb3840596cabf312f2bc88a4bb0b93a4e1ff5f` since the beginning of time (`startblock=0`) and merging them with existing data (if any) as using the `ledger` [merge strategy](https://docs.kamu.dev/cli/ingest/merge-strategies/).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Here we are using some **random person's account address** who performed many rETH transactions.\n",
    "    \n",
    "We picked it for illustration purposes only, and once you're done with the demo you can get this pipeline and **substitute your own wallet address**!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%import_dataset account.tokens.transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from `account.tokens.transfers` \n",
    "order by block_number desc\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select\n",
    "    token_name as `Token`, \n",
    "    sum(abs(value) / pow(10, token_decimal)) as `Volume Traded` \n",
    "from `account.tokens.transfers`\n",
    "group by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Try switching to **Bar** and **Pie** visualization types above.\n",
    "\n",
    "</div>\n",
    "\n",
    "As you can see the `account.tokens.transfers` dataset gives us the **number of tokens transfered**, and by looking at the `from` / `to` addresses we can tell if token was given or taken away out from our account.\n",
    "\n",
    "... But, we don't know **for how much** `ETH` the tokens were bought or sold for.\n",
    "\n",
    "This is why we need the `account.transactions` dataset that contains all account transactions along with their `ETH` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%import_dataset account.transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select *\n",
    "from `account.transactions` \n",
    "order by block_number desc\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -o transactions -q\n",
    "select\n",
    "    *, \n",
    "    value / pow(10, 18) as value_eth \n",
    "from `account.transactions` \n",
    "order by block_number desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "transactions\n",
    "transactions.hvplot.scatter(\n",
    "    x=\"block_time\",\n",
    "    y=\"value_eth\",\n",
    "    title=\"Account Transactions in ETH\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"ETH\",\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking token portfolio using derivative datasets\n",
    "\n",
    "To understand our \"portfolio\" of tokens we would like to have a dataset that:\n",
    "- Contains individual token transactions along with book/sell price in ETH\n",
    "- Tracks cummulative number of tokens held per each type\n",
    "- Tracks cummulative book price in ETH\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "We achieve this using the following derivative dataset:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">kamu add datasets/account.tokens.portfolio.yaml\n",
    "kamu pull account.tokens.portfolio\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "The key parts of this dataset look like this:\n",
    "\n",
    "```yaml\n",
    "---\n",
    "kind: DatasetSnapshot\n",
    "version: 1\n",
    "content:\n",
    "  name: account.tokens.investments\n",
    "  kind: derivative\n",
    "  metadata:\n",
    "    - kind: setTransform\n",
    "      inputs:\n",
    "        - name: account.tokens.transfers\n",
    "        - name: account.transactions\n",
    "      transform:\n",
    "        kind: sql\n",
    "        engine: flink\n",
    "        queries:\n",
    "          # Convert token transfers into (token_type, +/- delta) form\n",
    "          - alias: token_transfers\n",
    "            query: ...\n",
    "          # Convert ETH transactions into (transaction, +/- delta) form\n",
    "          - alias: transactions\n",
    "            query: ...\n",
    "          # JOIN the `token_transfers` and `transactions` datasets\n",
    "          - alias: token_transactions\n",
    "            query: |\n",
    "              select\n",
    "                tr.block_time,\n",
    "                tr.block_number,\n",
    "                tr.transaction_hash,\n",
    "                tx.symbol as account_symbol,\n",
    "                tr.token_symbol,\n",
    "                tr.token_amount,\n",
    "                tx.eth_amount\n",
    "              from token_transfers as tr\n",
    "              left join transactions as tx\n",
    "              on \n",
    "                tr.transaction_hash = tx.transaction_hash\n",
    "                and tr.block_time = tx.block_time\n",
    "          # Use a window function to calculate cumulative balance and book value\n",
    "          - alias: account.tokens.investments\n",
    "            query: >\n",
    "              select\n",
    "                *,\n",
    "                sum(token_amount) over (partition by token_symbol order by block_time) as token_balance,\n",
    "                sum(-eth_amount) over (partition by token_symbol order by block_time) as token_book_value_eth\n",
    "              from token_transactions\n",
    "```\n",
    "Remember that this is a **Streaming SQL** - we are not joining tables, but rather two potentially real-time and infinite streams of data. \n",
    "\n",
    "This particular type is a [Stream-to-Stream JOIN](https://docs.kamu.dev/cli/transform/joins-s2s/).\n",
    "\n",
    "In the next chapter we will explore why stream processing model is such a big deal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%import_dataset account.tokens.portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -o portfolio -q\n",
    "select * from `account.tokens.portfolio` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "portfolio[\n",
    "    portfolio.token_symbol == \"rETH\"\n",
    "].hvplot.scatter(\n",
    "    x=\"block_time\",\n",
    "    y=\"token_amount\",\n",
    "    color=\"orange\",\n",
    "    title=\"rETH Buy/Sell Transactions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "r = portfolio[\n",
    "    portfolio.token_symbol == \"rETH\"\n",
    "]\n",
    "r.hvplot.step(\n",
    "    x=\"block_time\",\n",
    "    xlabel=\"Time\",\n",
    "    y=\"token_balance\",\n",
    "    ylabel=\"rETH\",\n",
    "    title=\"rETH Amount Held\",\n",
    ") * r.hvplot.scatter(\n",
    "    x=\"block_time\",\n",
    "    y=\"token_balance\",\n",
    "    c=\"k\",\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Market Value\n",
    "The questions we would like to answer next are:\n",
    "- What our token portfolio's **market value in ETH**\n",
    "- What are the approximate **book and market values in USD**\n",
    "\n",
    "For the last one we will start with an intermidiate step (that will help us later) and create a derivative dataset with book values in USD per every portfolio transaction.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Add and pull the prepared dataset:\n",
    "    \n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">kamu add datasets/account.tokens.portfolio.usd.yaml\n",
    "kamu pull account.tokens.portfolio.usd\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Here's how this dataset is defined:\n",
    "\n",
    "```yaml\n",
    "---\n",
    "kind: DatasetSnapshot\n",
    "version: 1\n",
    "content:\n",
    "  name: account.tokens.portfolio.usd\n",
    "  kind: derivative\n",
    "  metadata:\n",
    "    - kind: setTransform\n",
    "      inputs:\n",
    "        - name: account.tokens.portfolio\n",
    "        - name: com.cryptocompare.ohlcv.eth-usd\n",
    "      transform:\n",
    "        kind: sql\n",
    "        engine: flink\n",
    "        # Set up temporal table functions that turn our stream of echange rates\n",
    "        # into a 3-dimenisonal (rows + columns + time) lookup table\n",
    "        temporalTables:\n",
    "          - name: com.cryptocompare.ohlcv.eth-usd\n",
    "            primaryKey:\n",
    "              - from_symbol\n",
    "        queries:\n",
    "          - alias: with_usd_amount\n",
    "            # Use Temporal Table JOIN to convert ETH to USD using exchange rate\n",
    "            # at the time of each individual transaction\n",
    "            query: |\n",
    "              select\n",
    "                tr.block_time,\n",
    "                tr.block_number,\n",
    "                tr.transaction_hash,\n",
    "                tr.account_symbol,\n",
    "                tr.token_symbol,\n",
    "                tr.token_amount,\n",
    "                tr.eth_amount,\n",
    "                tr.token_balance,\n",
    "                tr.token_book_value_eth,\n",
    "                'usd' as account_anchor_symbol,\n",
    "                (\n",
    "                  tr.eth_amount * eth2usd.`close`\n",
    "                ) as eth_amount_as_usd\n",
    "              from `account.tokens.portfolio` as tr\n",
    "              join `com.cryptocompare.ohlcv.eth-usd` for system_time as of tr.block_time as eth2usd\n",
    "              on tr.account_symbol = eth2usd.from_symbol and eth2usd.to_symbol = 'usd'\n",
    "          # Cummulative sum to derive the book value in USD\n",
    "          - alias: account.tokens.portfolio.usd\n",
    "            query: |\n",
    "              select\n",
    "                *,\n",
    "                sum(-eth_amount_as_usd) over (partition by token_symbol order by block_time) as token_book_value_eth_as_usd\n",
    "              from with_usd_amount\n",
    "    - kind: setVocab\n",
    "      eventTimeColumn: block_time\n",
    "```\n",
    "\n",
    "When converting between two currencies it's common for accountants to use some **average exchange rates** for a moth or event a whole year periods. \n",
    "\n",
    "<mark>This sacrifices accuracy for the sake of simplicity</mark> and would work poorly for cryptocurrencies that still exhibit a lot of volatility. \n",
    "\n",
    "Can we get **both accuracy and simpliticy**, so that for every single transaction we used the exchange rate as it was **at the time of that transaction**?\n",
    "\n",
    "This is where a [Temporal-Table JOIN](https://docs.kamu.dev/cli/learn/examples/stock-trading/#calculating-current-market-value-of-held-positions) can help us. It transforms an exchange rate stream into a kind of a lookup table which can be indexed by time to get the appropriate exhcange rate.\n",
    "\n",
    "Now we have a very rich dataset containing detailed information per every portfolio transaction, and also the **cumulative balance** of every position in the portfolio, i.e. the \"portfolio state\".\n",
    "\n",
    "The **market value** is basically how much money we would get at different points in time if we decided to liquidate our entire portfolio. To produce it we will use the same exact type of JOIN as before, but instead of joining exchange rates onto transactions we flip the direction and join the state of our portfolion onto every exchange rate data point.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Add and pull the prepared dataset:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu add datasets/account.tokens.portfolio.market-value.yaml\n",
    "&dollar; kamu pull account.tokens.portfolio.market-value\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Here's how the market value dataset is defined:\n",
    "\n",
    "\n",
    "```yaml\n",
    "---\n",
    "kind: DatasetSnapshot\n",
    "version: 1\n",
    "content:\n",
    "  name: account.tokens.portfolio.market-value\n",
    "  kind: derivative\n",
    "  metadata:\n",
    "    - kind: setTransform\n",
    "      inputs:\n",
    "        - name: account.tokens.portfolio.usd\n",
    "        - name: net.rocketpool.reth.mint-burn\n",
    "        - name: com.cryptocompare.ohlcv.eth-usd\n",
    "      transform:\n",
    "        kind: sql\n",
    "        engine: flink\n",
    "        temporalTables:\n",
    "          - name: account.tokens.portfolio.usd\n",
    "            primaryKey:\n",
    "              - token_symbol\n",
    "          - name: com.cryptocompare.ohlcv.eth-usd\n",
    "            primaryKey:\n",
    "              - from_symbol\n",
    "        queries:\n",
    "          # TODO: generate daily ticks?\n",
    "          - alias: market_value_reth2eth\n",
    "            query: |\n",
    "              select\n",
    "                rp.event_time,\n",
    "                tr.account_symbol,\n",
    "                tr.token_symbol,\n",
    "                tr.token_balance,\n",
    "                tr.token_book_value_eth,\n",
    "                (\n",
    "                  rp.eth_amount / rp.amount * tr.token_balance\n",
    "                ) as token_market_value_eth,\n",
    "                tr.token_book_value_eth_as_usd\n",
    "              from `net.rocketpool.reth.mint-burn` as rp\n",
    "              join `account.tokens.portfolio.usd` for system_time as of rp.event_time as tr\n",
    "              on rp.token_symbol = tr.token_symbol\n",
    "          - alias: account.tokens.portfolio.market-value\n",
    "            query: |\n",
    "              select\n",
    "                rp.event_time,\n",
    "                rp.account_symbol,\n",
    "                rp.token_symbol,\n",
    "                rp.token_balance,\n",
    "                rp.token_book_value_eth,\n",
    "                rp.token_market_value_eth,\n",
    "                rp.token_book_value_eth_as_usd,\n",
    "                (\n",
    "                  rp.token_market_value_eth * eth2usd.`close`\n",
    "                ) as token_market_value_usd\n",
    "              from market_value_reth2eth as rp\n",
    "              join `com.cryptocompare.ohlcv.eth-usd` for system_time as of rp.event_time as eth2usd\n",
    "              on eth2usd.from_symbol = rp.account_symbol and eth2usd.to_symbol = 'usd'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%import_dataset account.tokens.portfolio.market-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -o market_value -q\n",
    "select * from `account.tokens.portfolio.market-value` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "market_value.hvplot.line(\n",
    "    x=\"event_time\", \n",
    "    y=[\"token_book_value_eth\", \"token_market_value_eth\"],\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"ETH\",\n",
    "    legend=\"bottom_right\",\n",
    "    title=\"rETH: Book vs Market Value in ETH\",\n",
    "    height=500,\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "market_value.hvplot.line(\n",
    "    x=\"event_time\",\n",
    "    y=[\"token_book_value_eth_as_usd\", \"token_market_value_usd\"],\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"USD\",\n",
    "    legend=\"bottom_right\",\n",
    "    title=\"rETH: Book vs Market Value in USD\",\n",
    "    height=500,\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Phew... We've covered a lot of steps!\n",
    "\n",
    "To recap, here's the **outline of the pipeline** we just created:\n",
    "\n",
    "![blah](files/pipeline-1.png)\n",
    "\n",
    "```\n",
    "┌───────────────────────────────────────┬──────────────┬─────────────────────────────────────────────────┐\n",
    "│                 Name                  │     Kind     │                  Description                    │\n",
    "├───────────────────────────────────────┼──────────────┼─────────────────────────────────────────────────┤\n",
    "│ net.rocketpool.reth.mint-burn         │ Remote(Root) │ rETH transactions (pulled from IPFS)            │\n",
    "│ com.cryptocompare.ohlcv.eth-usd       │ Remote(Root) │ ETH to USD exchange rate (pulled from IPFS)     │\n",
    "│ account.tokens.transfers              │     Root     │ Wallet token transfers (sourced from Etherscan) │\n",
    "│ account.transactions                  │     Root     │ Wallet transactions (sourced from Etherscan)    │\n",
    "│ account.tokens.portfolio              │  Derivative  │ Tokens portfolio                                │\n",
    "│ account.tokens.portfolio.usd          │  Derivative  │ Tokens portfolio with USD book prices           │\n",
    "│ account.tokens.portfolio.market-value │  Derivative  │ Tokens portfolio market value in ETH and USD    │\n",
    "└───────────────────────────────────────┴──────────────┴─────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "Surely putting this pipeline togeter takes time. Things get much faster as you get more experience with different types of streaming JOINs. They get much-much faster if you collaborate and reuse pipelines made by others.\n",
    "\n",
    "The good thing is, whether you're ingesting external data or building processing pipelines with `kamu`, **you only have to do it once**. While data is flowing, your queries will continue to produce **up-to-date results with minimal maintenance effort**.\n",
    "\n",
    "We will cover some advanced aspects of why streaming pipelines are much more autonomous than batch in the next chapter, so please follow along!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://github.com/kamu-data/kamu-cli\">\n",
    "<img alt=\"kamu\" src=\"https://raw.githubusercontent.com/kamu-data/kamu-cli/master/docs/readme_files/kamu_logo.png\" width=270/>\n",
    "</a>\n",
    "</center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<center><i>World's first decentralized real-time data warehouse, on your laptop</i></center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div align=\"center\">\n",
    "<a href=\"https://docs.kamu.dev/cli/\">Docs</a> | \n",
    "<a href=\"https://docs.kamu.dev/cli/learn/learning-materials/\">Tutorials</a> | \n",
    "<a href=\"https://docs.kamu.dev/cli/learn/examples/\">Examples</a> |\n",
    "<a href=\"https://docs.kamu.dev/cli/get-started/faq/\">FAQ</a> |\n",
    "<a href=\"https://discord.gg/nU6TXRQNXC\">Discord</a> |\n",
    "<a href=\"https://kamu.dev\">Website</a>\n",
    "</div>\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "    \n",
    "# 1. Introduction\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome\n",
    "\n",
    "Hi, and thank you for checking out [kamu](https://github.com/kamu-data/kamu-cli) - the **new generation data management tool**!\n",
    "\n",
    "This environment comes with `kamu` command-line tool pre-installed, so give it a try now. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Your turn:</b> Open the <b>Terminal</b> tab in Jupyter and run:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<details>\n",
    "<summary style=\"display:list-item\"><b>New to Jupyter?</b></summary>\n",
    "\n",
    "* Go back to the Jupyter's <b>main tab</b> that shows the list of files \n",
    "* In the top right corner click <b>New -> Terminal</b>\n",
    "* Now you can switch between the terminal tab and this lesson as you continue\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "## What is Kamu for?\n",
    "\n",
    "[Kamu](https://github.com/kamu-data/kamu-cli) is a tool based on [Open Data Fabric](http://opendatafabric.org/) protocol that connects publishers and consumers of data into a <mark>decentralized data supply chain</mark>. It allows you to get data fast, in a ready-to-use form for analysis and ML tasks, ensure it is trustworthy and easy to keep up to date.\n",
    "\n",
    "In this demo, we are going to explore some of the key features of `kamu` through some <mark>real world examples</mark>.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Short on time?</b> See <a href=\"https://www.youtube.com/watch?v=oUTiWW6W78A&list=PLV91cS45lwVG20Hicztbv7hsjN6x69MJk\">this video</a> for a quick tour of key features.\n",
    "</div>\n",
    "\n",
    "If you have any questions throughout this demo - you can chat to us on [Discord](https://discord.gg/nU6TXRQNXC) or create an issue in [kamu-cli](https://github.com/kamu-data/kamu-cli) GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspaces\n",
    "\n",
    "You start working with `kamu` by creating a workspace. A workspace is just a directory where `kamu` stores data and metadata of the datasets.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Go ahead and create your first workspace (we'll do it right in the home directory):<br/>\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu init\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Similarly to `git` it will create a `.kamu` directory in the folder you ran the command in.\n",
    "</div>\n",
    "\n",
    "Your new workspace is currently empty. Confirm that by running:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu list\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the first dataset\n",
    "Let's add some new datasets to our workspace!\n",
    "\n",
    "In `kamu`, datasets are defined using `.yaml` files. You can import them with `kamu add` command. \n",
    "\n",
    "In this demo, we are going to work with some disagregated COVID-19 datasets published by different provinces of Canada.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "To add a dataset to the workspace run:<br/>\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu add demo/datasets/ca.bccdc.covid19.case-details.yaml\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Every command in <code>kamu</code> is well documented. Try running <code>kamu add -h</code> or <code>kamu add --help</code> to see all the parameters and useful examples.\n",
    "</div>\n",
    "\n",
    "This particular dataset includes case data form British Columbia, including day, age group, gender and area where the case was registered. Such datasets that ingest or receive external data are called `root` datasets and contain valuable data that cannot be reconstructed if lost (also known as **source data**).\n",
    "\n",
    "The dataset definition file looks like this:\n",
    "\n",
    "```yaml\n",
    "version: 1\n",
    "kind: DatasetSnapshot\n",
    "content:\n",
    "  id: ca.bccdc.covid19.case-details\n",
    "  source:\n",
    "    kind: root\n",
    "    fetch:\n",
    "      kind: url\n",
    "      url: http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv\n",
    "    read:\n",
    "      kind: csv\n",
    "      separator: ','\n",
    "      header: true\n",
    "      nullValue: ''\n",
    "    preprocess:\n",
    "        kind: sql\n",
    "        engine: spark\n",
    "        query: >\n",
    "          SELECT\n",
    "            CAST(UNIX_TIMESTAMP(Reported_Date, \"yyyy-MM-dd\") as TIMESTAMP) as reported_date,\n",
    "            Classification_Reported as classification,\n",
    "            id,\n",
    "            ha,\n",
    "            sex,\n",
    "            age_group\n",
    "          FROM input\n",
    "    merge:\n",
    "      kind: ledger\n",
    "      primaryKey:\n",
    "      - id\n",
    "  vocab:\n",
    "    eventTimeColumn: reported_date\n",
    "```\n",
    "\n",
    "As you can see, it tells `kamu` where to fetch the data from, what type of data to expect, and all the pre-processing steps needed to shape the data into a nice typed schema. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Kamu strictly follows <b>\"data as code\"</b> philosophy in which you never alter the data directly. Instead, you express all transformations with queries (SQL in this case).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling the data in\n",
    "\n",
    "We can now see the dataset in our workspace, but it is still empty:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu list\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "We told `kamu` where to get data from, but did not fetch it yet.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "So let's run the following command to fetch data:<br/>\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu pull ca.bccdc.covid19.case-details\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Make sure to use <b>shell completions</b>, they will save you a lot of typing!\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu pull c&lt;TAB&gt;\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "During this time `kamu` will fetch the data from its source, read and preprocess it as specified. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Once completed, we can use <code>tail</code> command to see a sample of the new data:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu tail ca.bccdc.covid19.case-details\n",
    "</code>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ledger nature of Data and Metadata \n",
    "\n",
    "A very important aspect of `kamu` is that it stores the history of data, not just snapshots. If we run the `pull` command on these datasets tomorrow, it will only add the records that were not previously observed.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Run <code>pull</code> command again to verify that our data is still up-to-date with the source:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu pull ca.bccdc.covid19.case-details\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "In other words, in `kamu` <mark>data is a ledger</mark> - an append-only record of events where past events never change (are immutable). The exact way how external data is transformed into a ledger is determined by the merge strategies documented [here](https://github.com/kamu-data/kamu-cli/blob/master/docs/merge_strategies.md).\n",
    "\n",
    "Additionally, every event that affects the dataset is stored in so-called **metadata chain**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Inspect the metadata chain using the <code>log</code> command (\"Q\" to close):\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu log ca.bccdc.covid19.case-details\n",
    "</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "As you can see, **metadata is also a ledger**! There are two metadata **blocks**:\n",
    "- First, corresponding to the dataset creation\n",
    "- Second, corresponding to N new records added by the last `pull`\n",
    "\n",
    "You can think of the metadata chain as `git` commit log, except instead of data - it stores an accurate **history of events** that affected how dataset looks like throughought its entire lifetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data\n",
    "\n",
    "Getting raw data in is just a small first step on our journey towards collaboration on data, but before we continue, let's take a quick break and see how you can analyze the data that we already have.\n",
    "\n",
    "### SQL Shell\n",
    "\n",
    "Kamu has a built-in SQL shell which you can start by running:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&dollar; kamu sql\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The default SQL shell is based on the <a href=\"https://spark.apache.org/\">Apache Spark</a>.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Once the shell starts, try the following queries:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&gt; show tables;</code>\n",
    "</p>\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&gt; describe `ca.bccdc.covid19.case-details`;</code>\n",
    "</p>\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">&gt; select * from `ca.bccdc.covid19.case-details` limit 10;</code>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Press **Ctrl + D** to exit.\n",
    "\n",
    "### Notebooks\n",
    "\n",
    "When you install `kamu` on your computer you can use `kamu notebook` command to start an integrated Jupyter \n",
    "Notebook environment, identical to the one you are currently using.\n",
    "\n",
    "Since we're already in the notebook environment - let's give this integration a try!\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Start by loading <code>kamu</code> Jupyter extension:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext kamu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<details>\n",
    "<summary style=\"display:list-item\"><b>New to Jupyter?</b></summary>\n",
    "\n",
    "Jupyter notebooks contain cells that are **executable**, so static text can me mixed with computations and data visualization.\n",
    "\n",
    "**You** are in control of what runs when, so you'll need to **select the code cell above** and then click the **\"Run\"** button on the top panel, or press `Shift + Enter`.\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "We can now import the dataset we have in our workspace into this notebook environment. We can also give it a less verbose alias.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Run the below to import the dataset (may take 15 or so seconds first time):\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%import_dataset ca.bccdc.covid19.case-details --alias bc_covid19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "To see the schema and number of records in the dataset run:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_covid19.printSchema()\n",
    "bc_covid19.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<details>\n",
    "<summary style=\"display:list-item\"><b>What did we just run?</b></summary>\n",
    "\n",
    "The code you type into a regular cell is executed by [PySpark](https://spark.apache.org/docs/latest/api/python/) server that `kamu` runs when you are working with notebooks.\n",
    "\n",
    "So it's a Python code, but it is **executed remotely**, not in the notebook kernel. We will discuss benefits of this later.\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "You can use the `%%sql` cell command to run SQL queries on the imported datasets.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "To see a sample of data run:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from bc_covid19 \n",
    "order by reported_date desc\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<details>\n",
    "<summary style=\"display:list-item\"><b>What did we just run?</b></summary>\n",
    "\n",
    "Similarly to the PySpark code, the queries in `%%sql` cells are sent to and executed by the Spark SQL engine. The results are then returned back to the notebook kernel.\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Let's run this simple SQL query to build a histogram of cases by the age group:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select\n",
    "    age_group,\n",
    "    count(*) as case_count \n",
    "from bc_covid19\n",
    "group by age_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Once you get the results, try using the built-in data visualizer to plot the data as a **bar chart**\n",
    "\n",
    "</div>\n",
    "\n",
    "SQL is great for shaping and aggregating data, but for more advanced processing or visualizations you might need more tools. Using `-o <variable_name>` parameter of the `%%sql` command we can ask for the result of a query to be returned into the notebook as **Pandas dataframe**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Let's count the number of cases per day and pull the result from Spark into our notebook:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -o df\n",
    "select\n",
    "    reported_date as date,\n",
    "    count(*) as case_count\n",
    "from bc_covid19\n",
    "group by Date\n",
    "order by Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a variable `df` containing the data as Pandas dataframe, and you are free to do with it anything you'd normally do in Jupyter.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Note that if you just type `df` in a cell - you will get an error. That's because by default this kernel executes operations in the remore PySpark environment. To access `df` you need to use `%%local` cell command which will execute code in this local Python kernel.\n",
    "    \n",
    "</div>\n",
    "\n",
    "This environment already comes with some popular plotting libraries pre-installed (like `plotly`, `bokeh`, `mapbox`, etc.), but if your favorite library is missing - you can always `pip install` it from the terminal.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Let's do some basic plotting:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(\n",
    "    df, x=\"date\", y=\"case_count\", \n",
    "    trendline=\"rolling\", trendline_options=dict(window=7), \n",
    "    trendline_color_override=\"red\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Up Next\n",
    "🎉 Well done so far! 🎉\n",
    "\n",
    "Now that we covered the basics of root datasets and data exploration - you are ready to move on to the next chapter where we will take a look at <mark>the key feature</mark> of `kamu` - **data collaboration**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

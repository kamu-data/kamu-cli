type AccessToken {
	accessToken: String!
	scope: String!
	tokenType: String!
}

interface Account {
	id: AccountID!
	name: String!
}

scalar AccountID

type AccountInfo {
	login: String!
	name: String!
	email: String
	avatarUrl: String
	gravatarId: String
}

scalar AccountName

type Accounts {
	"""
	Returns account by its ID
	"""
	byId(accountId: AccountID!): Account
	"""
	Returns account by its name
	"""
	byName(name: String!): Account
}

type AddData {
	inputCheckpoint: Multihash
	outputData: DataSlice
	outputCheckpoint: Checkpoint
	outputWatermark: DateTime
	sourceState: SourceState
}

type AttachmentEmbedded {
	path: String!
	content: String!
}

union Attachments = AttachmentsEmbedded

type AttachmentsEmbedded {
	items: [AttachmentEmbedded!]!
}

type Auth {
	githubLogin(code: String!): LoginResponse!
	accountInfo(accessToken: String!): AccountInfo!
}

type BlockInterval {
	start: Multihash!
	end: Multihash!
}

type BlockRef {
	name: String!
	blockHash: Multihash!
}


type Checkpoint {
	physicalHash: Multihash!
	size: Int!
}

interface CommitResult {
	message: String!
}

type CommitResultAppendError implements CommitResult {
	message: String!
}

type CommitResultSuccess implements CommitResult {
	oldHead: Multihash
	newHead: Multihash!
	message: String!
}

enum CompressionFormat {
	GZIP
	ZIP
}

interface CreateDatasetFromSnapshotResult {
	message: String!
}

interface CreateDatasetResult {
	message: String!
}

type CreateDatasetResultInvalidSnapshot implements CreateDatasetFromSnapshotResult {
	message: String!
}

type CreateDatasetResultMissingInputs implements CreateDatasetFromSnapshotResult {
	missingInputs: [String!]!
	message: String!
}

type CreateDatasetResultNameCollision implements CreateDatasetResult & CreateDatasetFromSnapshotResult {
	datasetName: DatasetName!
	message: String!
}

type CreateDatasetResultSuccess implements CreateDatasetResult & CreateDatasetFromSnapshotResult {
	dataset: Dataset!
	message: String!
}

type DataBatch {
	format: DataBatchFormat!
	content: String!
	numRecords: Int!
}

enum DataBatchFormat {
	JSON
	JSON_LD
	JSON_SOA
	CSV
}

type DataQueries {
	"""
	Executes a specified query and returns its result
	"""
	query(query: String!, queryDialect: QueryDialect!, dataFormat: DataBatchFormat, schemaFormat: DataSchemaFormat, limit: Int): DataQueryResult!
}

union DataQueryResult = DataQueryResultSuccess | DataQueryResultError

type DataQueryResultError {
	errorMessage: String!
	errorKind: DataQueryResultErrorKind!
}

enum DataQueryResultErrorKind {
	INVALID_SQL
	INTERNAL_ERROR
}

type DataQueryResultSuccess {
	schema: DataSchema
	data: DataBatch!
	limit: Int!
}

type DataSchema {
	format: DataSchemaFormat!
	content: String!
}

enum DataSchemaFormat {
	PARQUET
	PARQUET_JSON
}

type DataSlice {
	logicalHash: Multihash!
	physicalHash: Multihash!
	interval: OffsetInterval!
	size: Int!
}

type Dataset {
	"""
	Unique identifier of the dataset
	"""
	id: DatasetID!
	"""
	Symbolic name of the dataset.
	Name can change over the dataset's lifetime. For unique identifier use
	`id()`.
	"""
	name: DatasetName!
	"""
	Returns the user or organization that owns this dataset
	"""
	owner: Account!
	"""
	Returns the kind of a dataset (Root or Derivative)
	"""
	kind: DatasetKind!
	"""
	Access to the data of the dataset
	"""
	data: DatasetData!
	"""
	Access to the metadata of the dataset
	"""
	metadata: DatasetMetadata!
	"""
	Creation time of the first metadata block in the chain
	"""
	createdAt: DateTime!
	"""
	Creation time of the most recent metadata block in the chain
	"""
	lastUpdatedAt: DateTime!
}

type DatasetConnection {
	"""
	A shorthand for `edges { node { ... } }`
	"""
	nodes: [Dataset!]!
	"""
	Approximate number of total nodes
	"""
	totalCount: Int!
	"""
	Page information
	"""
	pageInfo: PageBasedInfo!
	edges: [DatasetEdge!]!
}

type DatasetData {
	"""
	Total number of records in this dataset
	"""
	numRecordsTotal: Int!
	"""
	An estimated size of data on disk not accounting for replication or
	caching
	"""
	estimatedSize: Int!
	"""
	Returns the specified number of the latest records in the dataset
	This is equivalent to the SQL query: `SELECT * FROM dataset ORDER BY
	event_time DESC LIMIT N`
	"""
	tail(limit: Int, dataFormat: DataBatchFormat, schemaFormat: DataSchemaFormat): DataQueryResult!
}

type DatasetEdge {
	node: Dataset!
}

scalar DatasetID

enum DatasetKind {
	ROOT
	DERIVATIVE
}

type DatasetMetadata {
	"""
	Access to the temporal metadata chain of the dataset
	"""
	chain: MetadataChain!
	"""
	Last recorded watermark
	"""
	currentWatermark: DateTime
	"""
	Latest data schema
	"""
	currentSchema(format: DataSchemaFormat): DataSchema
	"""
	Current upstream dependencies of a dataset
	"""
	currentUpstreamDependencies: [Dataset!]!
	"""
	Current downstream dependencies of a dataset
	"""
	currentDownstreamDependencies: [Dataset!]!
	"""
	Current source used by the root dataset
	"""
	currentSource: SetPollingSource
	"""
	Current transformation used by the derivative dataset
	"""
	currentTransform: SetTransform
	"""
	Current descriptive information about the dataset
	"""
	currentInfo: SetInfo!
	"""
	Current readme file as discovered from attachments associated with the
	dataset
	"""
	currentReadme: String
	"""
	Current license associated with the dataset
	"""
	currentLicense: SetLicense
	"""
	Current vocabulary associated with the dataset
	"""
	currentVocab: SetVocab
}

scalar DatasetName

type Datasets {
	"""
	Returns dataset by its ID
	"""
	byId(datasetId: DatasetID!): Dataset
	"""
	Returns dataset by its owner and name
	"""
	byOwnerAndName(accountName: AccountName!, datasetName: DatasetName!): Dataset
	"""
	Returns datasets belonging to the specified account
	"""
	byAccountId(accountId: AccountID!, page: Int, perPage: Int): DatasetConnection!
	"""
	Returns datasets belonging to the specified account
	"""
	byAccountName(accountName: AccountName!, page: Int, perPage: Int): DatasetConnection!
	"""
	Creates a new empty dataset
	"""
	createEmpty(accountId: AccountID!, datasetKind: DatasetKind!, datasetName: DatasetName!): CreateDatasetResult!
	"""
	Creates a new dataset from provided DatasetSnapshot manifest
	"""
	createFromSnapshot(accountId: AccountID!, snapshot: String!, snapshotFormat: MetadataManifestFormat!): CreateDatasetFromSnapshotResult!
}

"""
Implement the DateTime<Utc> scalar

The input/output is a string in RFC3339 format.
"""
scalar DateTime

type EnvVar {
	name: String!
	value: String
}

union EventTimeSource = EventTimeSourceFromMetadata | EventTimeSourceFromPath

type EventTimeSourceFromMetadata {
	dummy: String
}

type EventTimeSourceFromPath {
	pattern: String!
	timestampFormat: String
}

type ExecuteQuery {
	inputSlices: [InputSlice!]!
	inputCheckpoint: Multihash
	outputData: DataSlice
	outputCheckpoint: Checkpoint
	outputWatermark: DateTime
}

union FetchStep = FetchStepUrl | FetchStepFilesGlob | FetchStepContainer

type FetchStepContainer {
	image: String!
	command: [String!]
	args: [String!]
	env: [EnvVar!]
}

type FetchStepFilesGlob {
	path: String!
	eventTime: EventTimeSource
	cache: SourceCaching
	order: SourceOrdering
}

type FetchStepUrl {
	url: String!
	eventTime: EventTimeSource
	cache: SourceCaching
	headers: [RequestHeader!]
}



type InputSlice {
	datasetId: DatasetID!
	blockInterval: BlockInterval
	dataInterval: OffsetInterval
}


type LoginResponse {
	token: AccessToken!
	accountInfo: AccountInfo!
}

union MergeStrategy = MergeStrategyAppend | MergeStrategyLedger | MergeStrategySnapshot

type MergeStrategyAppend {
	dummy: String
}

type MergeStrategyLedger {
	primaryKey: [String!]!
}

type MergeStrategySnapshot {
	primaryKey: [String!]!
	compareColumns: [String!]
	observationColumn: String
	obsvAdded: String
	obsvChanged: String
	obsvRemoved: String
}

type MetadataBlockConnection {
	"""
	A shorthand for `edges { node { ... } }`
	"""
	nodes: [MetadataBlockExtended!]!
	"""
	Approximate number of total nodes
	"""
	totalCount: Int!
	"""
	Page information
	"""
	pageInfo: PageBasedInfo!
	edges: [MetadataBlockEdge!]!
}

type MetadataBlockEdge {
	node: MetadataBlockExtended!
}

type MetadataBlockExtended {
	blockHash: Multihash!
	prevBlockHash: Multihash
	systemTime: DateTime!
	author: Account!
	event: MetadataEvent!
	sequenceNumber: Int!
}

type MetadataChain {
	"""
	Returns all named metadata block references
	"""
	refs: [BlockRef!]!
	"""
	Returns a metadata block corresponding to the specified hash
	"""
	blockByHash(hash: Multihash!): MetadataBlockExtended
	"""
	Returns a metadata block corresponding to the specified hash and encoded
	in desired format
	"""
	blockByHashEncoded(hash: Multihash!, format: MetadataManifestFormat!): String
	"""
	Iterates all metadata blocks in the reverse chronological order
	"""
	blocks(page: Int, perPage: Int): MetadataBlockConnection!
	"""
	Commits new event to the metadata chain
	"""
	commitEvent(event: String!, eventFormat: MetadataManifestFormat!): CommitResult!
}

union MetadataEvent = AddData | ExecuteQuery | Seed | SetPollingSource | SetTransform | SetVocab | SetWatermark | SetAttachments | SetInfo | SetLicense

enum MetadataManifestFormat {
	YAML
}

type MetadataManifestMalformed implements CommitResult & CreateDatasetFromSnapshotResult {
	message: String!
}

type MetadataManifestUnsupportedVersion implements CommitResult & CreateDatasetFromSnapshotResult {
	message: String!
}

scalar Multihash

type Mutation {
	auth: Auth!
}

type OffsetInterval {
	start: Int!
	end: Int!
}

type Organization implements Account {
	"""
	Unique and stable identitfier of this organization account
	"""
	id: AccountID!
	"""
	Symbolic account name
	"""
	name: String!
}

type PageBasedInfo {
	"""
	When paginating backwards, are there more items?
	"""
	hasPreviousPage: Boolean!
	"""
	When paginating forwards, are there more items?
	"""
	hasNextPage: Boolean!
	"""
	Index of the current page
	"""
	currentPage: Int!
	"""
	Approximate number of total pages assuming number of nodes per page
	stays the same
	"""
	totalPages: Int
}

union PrepStep = PrepStepDecompress | PrepStepPipe

type PrepStepDecompress {
	format: CompressionFormat!
	subPath: String
}

type PrepStepPipe {
	command: [String!]!
}

type Query {
	"""
	Returns the version of the GQL API
	"""
	apiVersion: String!
	"""
	Dataset-related functionality group
	"""
	datasets: Datasets!
	"""
	Account-related functionality group
	"""
	accounts: Accounts!
	"""
	Search-related functionality group
	"""
	search: Search!
	"""
	Querying and data manipulations
	"""
	data: DataQueries!
}

enum QueryDialect {
	DATA_FUSION
}

union ReadStep = ReadStepCsv | ReadStepJsonLines | ReadStepGeoJson | ReadStepEsriShapefile | ReadStepParquet

type ReadStepCsv {
	schema: [String!]
	separator: String
	encoding: String
	quote: String
	escape: String
	comment: String
	header: Boolean
	enforceSchema: Boolean
	inferSchema: Boolean
	ignoreLeadingWhiteSpace: Boolean
	ignoreTrailingWhiteSpace: Boolean
	nullValue: String
	emptyValue: String
	nanValue: String
	positiveInf: String
	negativeInf: String
	dateFormat: String
	timestampFormat: String
	multiLine: Boolean
}

type ReadStepEsriShapefile {
	schema: [String!]
	subPath: String
}

type ReadStepGeoJson {
	schema: [String!]
}

type ReadStepJsonLines {
	schema: [String!]
	dateFormat: String
	encoding: String
	multiLine: Boolean
	primitivesAsString: Boolean
	timestampFormat: String
}

type ReadStepParquet {
	schema: [String!]
}

type RequestHeader {
	name: String!
	value: String!
}

type Search {
	"""
	Perform search across all resources
	"""
	query(query: String!, page: Int, perPage: Int): SearchResultConnection!
}

union SearchResult = Dataset

type SearchResultConnection {
	"""
	A shorthand for `edges { node { ... } }`
	"""
	nodes: [SearchResult!]!
	"""
	Approximate number of total nodes
	"""
	totalCount: Int!
	"""
	Page information
	"""
	pageInfo: PageBasedInfo!
	edges: [SearchResultEdge!]!
}

type SearchResultEdge {
	node: SearchResult!
}

type Seed {
	datasetId: DatasetID!
	datasetKind: DatasetKind!
}

type SetAttachments {
	attachments: Attachments!
}

type SetInfo {
	description: String
	keywords: [String!]
}

type SetLicense {
	shortName: String!
	name: String!
	spdxId: String
	websiteUrl: String!
}

type SetPollingSource {
	fetch: FetchStep!
	prepare: [PrepStep!]
	read: ReadStep!
	preprocess: Transform
	merge: MergeStrategy!
}

type SetTransform {
	inputs: [TransformInput!]!
	transform: Transform!
}

type SetVocab {
	systemTimeColumn: String
	eventTimeColumn: String
	offsetColumn: String
}

type SetWatermark {
	outputWatermark: DateTime!
}

union SourceCaching = SourceCachingForever

type SourceCachingForever {
	dummy: String
}

enum SourceOrdering {
	BY_EVENT_TIME
	BY_NAME
}

type SourceState {
	kind: String!
	source: String!
	value: String!
}

type SqlQueryStep {
	alias: String
	query: String!
}


type TemporalTable {
	name: String!
	primaryKey: [String!]!
}

union Transform = TransformSql

type TransformInput {
	id: DatasetID
	name: DatasetName!
	dataset: Dataset!
}

type TransformSql {
	engine: String!
	version: String
	queries: [SqlQueryStep!]!
	temporalTables: [TemporalTable!]
}

type User implements Account {
	"""
	Unique and stable identitfier of this user account
	"""
	id: AccountID!
	"""
	Symbolic account name
	"""
	name: String!
}

schema {
	query: Query
	mutation: Mutation
}
